---
id: week-04-ros2-packages-python
title: Week 4 – Building ROS 2 Packages with Python and rclpy
---

# Week 4: Building ROS 2 Packages with Python and rclpy

## Learning Objectives

By the end of this week, students will be able to:
- Create and structure ROS 2 packages for humanoid robot applications
- Implement ROS 2 nodes using Python and rclpy
- Design custom message and service types for humanoid robotics
- Use launch files to orchestrate complex robot systems
- Interface Python-based AI agents with ROS 2 controllers

## Creating ROS 2 Packages

ROS 2 packages are the fundamental building blocks of robot applications. For humanoid robots, packages typically represent specific capabilities like walking control, vision processing, or speech recognition.

### Package Structure

A standard ROS 2 package includes:

```
my_robot_package/
├── CMakeLists.txt          # Build configuration for C++
├── package.xml             # Package metadata
├── setup.py                # Python setup
├── setup.cfg               # Installation configuration
├── resource/               # Package resources
├── test/                   # Unit tests
└── my_robot_package/       # Python modules
    ├── __init__.py
    └── nodes/              # Node implementations
```

### Creating a New Package

```bash
cd ~/ros2_ws/src
ros2 pkg create --build-type ament_python my_humanoid_controller
```

This creates a basic Python package structure ready for humanoid robot development.

## Implementing ROS 2 Nodes with rclpy

rclpy is the Python client library for ROS 2, providing the interface between Python code and the ROS 2 middleware. It's particularly important for humanoid robotics as many AI algorithms are implemented in Python.

### Basic Node Structure

```python
import rclpy
from rclpy.node import Node

class HumanoidController(Node):
    def __init__(self):
        super().__init__('humanoid_controller')
        # Initialize node components here
        self.get_logger().info('Humanoid Controller node initialized')

def main(args=None):
    rclpy.init(args=args)
    controller = HumanoidController()
    rclpy.spin(controller)
    controller.destroy_node()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
```

### Publishers and Subscribers

For humanoid robots, common publishers and subscribers handle:

- Joint state information
- Sensor data (IMU, cameras, force sensors)
- Control commands
- Robot state updates

```python
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import JointState
from std_msgs.msg import Float64MultiArray

class JointStatePublisher(Node):
    def __init__(self):
        super().__init__('joint_state_publisher')
        
        # Publisher for joint commands
        self.joint_cmd_publisher = self.create_publisher(
            Float64MultiArray, 
            'joint_commands', 
            10
        )
        
        # Subscriber for joint feedback
        self.joint_state_subscriber = self.create_subscription(
            JointState,
            'joint_states',
            self.joint_state_callback,
            10
        )
        
        # Timer for periodic publishing
        self.timer = self.create_timer(0.05, self.timer_callback)  # 20 Hz
        
    def joint_state_callback(self, msg):
        # Process joint state feedback
        self.get_logger().info(f'Received joint states: {len(msg.name)} joints')
        
    def timer_callback(self):
        # Publish joint commands
        cmd_msg = Float64MultiArray()
        # Calculate desired joint positions based on control logic
        cmd_msg.data = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]  # Example values
        self.joint_cmd_publisher.publish(cmd_msg)
```

## Custom Message and Service Types

Humanoid robots often require custom message types to represent specific data structures:

### Creating Custom Messages

1. Create a `msg/` directory in your package
2. Define your message in a `.msg` file
3. Update `package.xml` and `setup.py` to include message generation

Example custom message for humanoid pose:
```
# In msg/HumanoidPose.msg
float64[3] position     # x, y, z position of robot
float64[4] orientation  # quaternion (x, y, z, w)
float64[28] joint_angles # 28 joint angles for humanoid
uint8 state            # robot state (standing, walking, etc.)
```

### Using Custom Messages

```python
from my_humanoid_msgs.msg import HumanoidPose

class PoseController(Node):
    def __init__(self):
        super().__init__('pose_controller')
        self.pose_publisher = self.create_publisher(
            HumanoidPose,
            'robot_pose',
            10
        )
    
    def publish_pose(self, position, orientation, joint_angles):
        pose_msg = HumanoidPose()
        pose_msg.position = position
        pose_msg.orientation = orientation
        pose_msg.joint_angles = joint_angles
        pose_msg.state = 1  # standing
        self.pose_publisher.publish(pose_msg)
```

## Launch Files for System Orchestration

Launch files allow you to start multiple nodes with a single command, essential for complex humanoid robots with many components.

### Basic Launch File

```python
# launch/humanoid_system.launch.py
from launch import LaunchDescription
from launch_ros.actions import Node

def generate_launch_description():
    return LaunchDescription([
        Node(
            package='my_humanoid_controller',
            executable='joint_controller',
            name='joint_controller',
            parameters=[
                {'kp': 10.0},
                {'ki': 0.1},
                {'kd': 0.05}
            ]
        ),
        Node(
            package='my_humanoid_controller',
            executable='sensor_processor',
            name='sensor_processor',
            parameters=[
                {'imu_topic': '/imu/data'},
                {'camera_topic': '/camera/image_raw'}
            ]
        ),
        Node(
            package='my_humanoid_controller',
            executable='behavior_controller',
            name='behavior_controller'
        )
    ])
```

### Parameter Management

Launch files can also manage parameters for different robot configurations:

```python
# launch/humanoid_with_params.launch.py
from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument
from launch.substitutions import LaunchConfiguration
from launch_ros.actions import Node

def generate_launch_description():
    # Declare launch arguments
    robot_name_launch_arg = DeclareLaunchArgument(
        'robot_name',
        default_value='my_humanoid',
        description='Name of the robot'
    )
    
    return LaunchDescription([
        robot_name_launch_arg,
        Node(
            package='my_humanoid_controller',
            executable='joint_controller',
            name=[LaunchConfiguration('robot_name'), '_joint_controller'],
            parameters=[
                {'control_frequency': 100},
                {'max_joint_velocity': 2.0}
            ]
        )
    ])
```

## Integrating AI Agents with ROS 2

One of the key advantages of ROS 2 is its ability to integrate AI agents with robot control systems. Python makes this integration particularly straightforward.

### AI Agent Node Example

```python
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from sensor_msgs.msg import Image
import cv2
from cv_bridge import CvBridge
import numpy as np

class AIBrainNode(Node):
    def __init__(self):
        super().__init__('ai_brain')
        
        # Bridge for converting ROS images to OpenCV
        self.bridge = CvBridge()
        
        # Subscribers for sensor data
        self.image_subscriber = self.create_subscription(
            Image,
            'camera/image_raw',
            self.image_callback,
            10
        )
        
        # Publishers for robot commands
        self.command_publisher = self.create_publisher(
            String,
            'robot_commands',
            10
        )
        
        # Timer for AI processing
        self.ai_timer = self.create_timer(0.5, self.ai_processing_callback)
        
    def image_callback(self, msg):
        # Convert ROS image to OpenCV format
        cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        
        # Store image for AI processing
        self.last_image = cv_image
        
    def ai_processing_callback(self):
        if hasattr(self, 'last_image'):
            # Process image with AI model
            result = self.process_with_ai(self.last_image)
            
            # Publish command based on AI decision
            cmd_msg = String()
            cmd_msg.data = result
            self.command_publisher.publish(cmd_msg)
    
    def process_with_ai(self, image):
        # Placeholder for actual AI processing
        # This could be object detection, scene understanding, etc.
        height, width, _ = image.shape
        center_x, center_y = width // 2, height // 2
        
        # Simple example: detect if there's an object in the center
        center_region = image[center_y-50:center_y+50, center_x-50:center_x+50]
        avg_color = np.mean(center_region, axis=(0,1))
        
        if avg_color[2] > 100:  # If red component is high
            return "move_forward"
        else:
            return "turn_left"
```

## Best Practices for Humanoid Robotics

### Node Design

1. **Single Responsibility**: Each node should have a well-defined purpose (e.g., sensor processing, motor control, AI decision-making)

2. **Modularity**: Design nodes to be reusable across different humanoid robot platforms

3. **Error Handling**: Implement robust error handling for sensor failures, communication issues, etc.

### Message Design

1. **Efficiency**: Keep message sizes reasonable for real-time communication
2. **Clarity**: Use descriptive field names that clearly indicate their purpose
3. **Extensibility**: Design messages to accommodate future enhancements

### Performance Considerations

1. **Timing**: Be mindful of timing requirements for real-time robot control
2. **Resource Usage**: Monitor CPU and memory usage, especially on robot hardware
3. **Communication**: Optimize message rates based on actual requirements

## Testing and Debugging

ROS 2 provides several tools for testing and debugging:

### Command Line Tools

```bash
# Check active nodes
ros2 node list

# Check topics
ros2 topic list

# Echo messages on a topic
ros2 topic echo /joint_states

# Call a service
ros2 service call /set_joint_positions my_robot_msgs/srv/SetJointPositions "{positions: [0.1, 0.2, 0.3]}"
```

### Logging

```python
# Use ROS 2 logging instead of print statements
self.get_logger().info('Joint position command sent')
self.get_logger().warn('Joint limit approaching')
self.get_logger().error('Critical error in control loop')
```

## Key Challenges and Practical Insights

Developing ROS 2 packages for humanoid robots presents several challenges:

1. **Real-time Performance**: Python's Global Interpreter Lock (GIL) can affect real-time performance. Consider using C++ for time-critical control loops.

2. **Complexity Management**: Humanoid robots have many interacting components. Careful system design and modularity are essential.

3. **Integration**: Bridging AI algorithms with robot control requires careful consideration of timing, data formats, and error handling.

4. **Safety**: Implement safety mechanisms to prevent robot damage or injury during development and operation.

## Looking Ahead

In Week 5, we'll continue exploring ROS 2 by focusing on advanced concepts like actions for long-running tasks, parameter servers for configuration management, and advanced launch file techniques. We'll also examine how to integrate more complex AI models with ROS 2 systems.